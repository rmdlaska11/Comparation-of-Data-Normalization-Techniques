# -*- coding: utf-8 -*-
"""Skripsi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cbCwWqLca1VKtnDaARLincgHUbs0MMfS

#Import Library
"""

# Import library yang diperlukan
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.metrics import specificity_score, sensitivity_score
from yellowbrick.target import ClassBalance

from google.colab import drive
drive.mount('/content/drive')

"""#Import Data"""

data = pd.read_excel('/content/drive/MyDrive/Skripsi/Data/Data Curah Hujan 2019-2023.xlsx')
data

data.info()

"""#Preprocessing"""

data.isnull().sum()

# Interpolasi linear
data.interpolate(method='linear', inplace=True)

# Fungsi untuk mengubah nilai curah hujan ke kategori yang diberikan
def categorize_curah_hujan(curah_hujan):
    if curah_hujan <= 0.5:
        return 'Tidak Hujan'
    else:
        return 'Hujan'

# Terapkan fungsi pada kolom 'Curah_Hujan' untuk membuat kolom baru 'Kategori_Curah_Hujan'
data['RR_c'] = data['RR'].apply(categorize_curah_hujan)

# Tampilkan DataFrame hasil
print(data)

# Fungsi untuk mengubah nilai curah hujan menjadi kategori angka
def map_curah_hujan_to_numeric(curah_hujan):
    if curah_hujan <= 0.5:
        return 0
    else:
        return 1

# Terapkan fungsi pada kolom 'Curah_Hujan' untuk membuat kolom baru 'Numeric_Curah_Hujan'
data['Y'] = data['RR'].apply(map_curah_hujan_to_numeric)

# Tampilkan DataFrame hasil
data

data.to_excel('Data Curah Hujan 2019-2023 (interpolasi).xlsx')

"""#Statistika Deskriptif"""

# Hitung jumlah hujan dan tidak hujan
tidak_hujan = data["RR_c"].value_counts()[1]
hujan = data["RR_c"].value_counts()[0]

# Buat pie chart
labels = ["Hujan", "Tidak Hujan"]
sizes = [hujan, tidak_hujan]
colors = ["#E74C3C", "#F1C40F"]

plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%')
plt.show()

data.describe()

data.groupby('Y').size()

X = data.loc[:,[ 'X1', 'X2', 'X3', 'X4', 'X5']]
y = data["Y"]
print(X)
print(y)

"""#Without Normalization"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35, stratify = y)

print(X_train.shape)
print(X_test.shape)

data_test = pd.DataFrame(y_test)
data_test.to_excel('Data testing.xlsx')

model = SVC()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
pred_tanpa = pd.DataFrame(y_pred)

print("hasil prediksi: kategori curah hujan (tanpa normalisasi)", pred_tanpa)

pred_tanpa.to_excel('Data Prediksi (tanpa).xlsx')

accuracy = accuracy_score(y_test, y_pred)
spesifisitas = specificity_score(y_test, y_pred)
sensitivitas = sensitivity_score(y_test, y_pred)

print("Accuracy:", accuracy)
print(f"Spesifisitas: {spesifisitas}")
print(f"Sensitivitas: {sensitivitas}")

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""#Z Score Normalization"""

scaler = StandardScaler()
X_zscore = scaler.fit_transform(X)

Zscore = pd.DataFrame(X_zscore)

Zscore.to_excel('Data Curah Hujan 2019-2023 (Z-score).xlsx')

Zscore.describe()

X_train_zscore, X_test_zscore, y_train_zscore, y_test_zscore = train_test_split(X_zscore, y, test_size=0.2, random_state=35, stratify = y)

from yellowbrick.target import ClassBalance
visualizer = ClassBalance(labels=[0, 1])
visualizer.fit(y_train_zscore, y_test_zscore)
visualizer.poof()

data_test_zscore = pd.DataFrame(y_test_zscore)
data_test_zscore.to_excel('Data testing (zscore).xlsx')

model_zscore = SVC()
model_zscore.fit(X_train_zscore, y_train_zscore)

y_pred_zscore = model_zscore.predict(X_test_zscore)
pred_zscore = pd.DataFrame(y_pred_zscore)

print("hasil prediksi: kategori curah hujan (zscore)", pred_zscore)

pred_zscore.to_excel('Data Prediksi (zscore).xlsx')

accuracy_zscore = accuracy_score(y_test_zscore, y_pred_zscore)
spesifisitas = specificity_score(y_test_zscore, y_pred_zscore)
sensitivitas = sensitivity_score(y_test_zscore, y_pred_zscore)

print("Accuracy:", accuracy_zscore)
print(f"Spesifisitas: {spesifisitas}")
print(f"Sensitivitas: {sensitivitas}")

print(confusion_matrix(y_test_zscore, y_pred_zscore))
print(classification_report(y_test_zscore, y_pred_zscore))

"""#Min-Max Normalization"""

minmax = MinMaxScaler()
X_minmax = minmax.fit_transform(X)

minmax = pd.DataFrame(X_minmax)

minmax.to_excel('Data Curah Hujan 2019-2023 (minmax).xlsx')

minmax.describe()

X_train_minmax, X_test_minmax, y_train_minmax, y_test_minmax = train_test_split(X_minmax, y, test_size=0.2, random_state=35, stratify = y)

model_minmax = SVC()
model_minmax.fit(X_train_minmax, y_train_minmax)

y_pred_minmax = model_minmax.predict(X_test_minmax)
pred_minmax = pd.DataFrame(y_pred_minmax)

print("hasil prediksi: kategori curah hujan (minmax)", pred_minmax)

pred_minmax.to_excel('Data Prediksi (minmax).xlsx')

accuracy_minmax = accuracy_score(y_test_minmax, y_pred_minmax)
spesifisitas = specificity_score(y_test_minmax, y_pred_minmax)
sensitivitas = sensitivity_score(y_test_minmax, y_pred_minmax)

print("Accuracy:", accuracy_minmax)
print(f"Spesifisitas: {spesifisitas}")
print(f"Sensitivitas: {sensitivitas}")

print(confusion_matrix(y_test_minmax, y_pred_minmax))
print(classification_report(y_test_minmax, y_pred_minmax))

"""#Robust Normalization"""

robust = RobustScaler()
X_robust = robust.fit_transform(X)

robust = pd.DataFrame(X_robust)

robust.to_excel('Data Curah Hujan 2019-2023 (robust).xlsx')

robust.describe()

X_train_robust, X_test_robust, y_train_robust, y_test_robust = train_test_split(X_robust, y, test_size=0.2, random_state=35, stratify = y)

model_robust = SVC()
model_robust.fit(X_train_robust, y_train_robust)

y_pred_robust = model_robust.predict(X_test_robust)
pred_robust = pd.DataFrame(y_pred_robust)

print("hasil prediksi: kategori curah hujan (robust)", pred_robust)

pred_robust.to_excel('Data Prediksi (robust).xlsx')

accuracy_robust = accuracy_score(y_test_robust, y_pred_robust)
spesifisitas = specificity_score(y_test_robust, y_pred_robust)
sensitivitas = sensitivity_score(y_test_robust, y_pred_robust)

print("Accuracy:", accuracy_robust)
print(f"Spesifisitas: {spesifisitas}")
print(f"Sensitivitas: {sensitivitas}")

print(confusion_matrix(y_test_robust, y_pred_robust))
print(classification_report(y_test_robust, y_pred_robust))

"""#Max Absolut Normalization"""

maxabs = MaxAbsScaler()
X_maxabs = maxabs.fit_transform(X)

maxabs = pd.DataFrame(X_maxabs)

maxabs.to_excel('Data Curah Hujan 2019-2023 (maxabs).xlsx')

maxabs.describe()

X_train_maxabs, X_test_maxabs, y_train_maxabs, y_test_maxabs = train_test_split(X_maxabs, y, test_size=0.2, random_state=35, stratify = y)

model_maxabs = SVC()
model_maxabs.fit(X_train_maxabs, y_train_maxabs)

y_pred_maxabs = model_maxabs.predict(X_test_maxabs)
pred_maxabs = pd.DataFrame(y_pred_maxabs)

print("hasil prediksi: kategori curah hujan (maxabs)", pred_maxabs)

pred_maxabs.to_excel('Data Prediksi (maxabs).xlsx')

accuracy_maxabs = accuracy_score(y_test_maxabs, y_pred_maxabs)
spesifisitas = specificity_score(y_test_maxabs, y_pred_maxabs)
sensitivitas = sensitivity_score(y_test_maxabs, y_pred_maxabs)

print("Accuracy:", accuracy_maxabs)
print(f"Spesifisitas: {spesifisitas}")
print(f"Sensitivitas: {sensitivitas}")

print(confusion_matrix(y_test_maxabs, y_pred_maxabs))
print(classification_report(y_test_maxabs, y_pred_maxabs))